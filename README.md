# Классификатор новостей

Этот проект создан с целью предоставления способа анализа новостей, обеспечивая пользователям доступ к автоматизированной системе классификации новостных статей. Используя современные методы машинного обучения, проект обеспечивает точную и эффективную классификацию новостей по различным категориям, делая процесс оценки информации быстрым и надежным.

Этот инструмент помогает пользователям оперативно получать представление о содержании новостей, выделяя ключевые темы и категории. Благодаря возможности автоматической обработки и классификации новостей, пользователи могут экономить время на чтении и анализе большого объема информации, сосредотачиваясь на наиболее важных для них новостях.

Веб-приложение, разработанное в рамках этого проекта, представляет собой удобный и доступный способ взаимодействия с системой. Пользователи могут отправлять новостные статьи для анализа и получать быстрые и точные результаты классификации, что позволяет им оперативно ориентироваться во всесторонней потоке информации и принимать информированные решения на основе выделенных категорий.

Этот проект отличается не только функциональностью, но и своей значимостью в контексте современного информационного общества, где оперативный анализ и оценка новостей являются ключевыми элементами принятия обоснованных решений.

### Возможности

- 
-
-


### Установка

Проект поделен на несколько подпроектов.

В данной инструкции рассмотрим работу со всем проектом в целом, на одном сервере.

Чтобы скачать проект, выполните следующие шаги:

1. Клонируйте репозиторий:

   ```bash
   https://github.com/Gray-Starling/classifier_and_news_collector.git
   cd classifier_and_news_collector
   ```

2. Установите необходимые зависимости:

   ```bash
   pip install -r requirements.txt
   ```

3. Настройте переменные окружения. Создайте файл `.env` в корневом каталоге
 
### Структура проекта

```python
classifier_and_news_collector/
├── ml_news_classifier/ # Каталог подпроекта по обучению модели 
|   ├── data/ # Каталог данных
|   |   ├── processed/ # Каталог обработанных данных
|   |   |   ├── data.csv # Обработанные данные
|   |   |
|   |   ├── source/ # Каталог сырого датасета
|   |   |   ├── news_dataset.csv # Не обработанные данные
|   |   |
|   |   ├── get_data.py # Получение сырого датасета по API
|
├── parser_server/ # Каталог подпроекта по сбору данных 
|   ├── data/ # Каталог данных
|   |   ├── news_data.csv # Собранные данные
|   |
|   ├── logs/ # Каталог логов
|   |   ├── scrapper/
|   |   |   ├── ...
|   |   |
|   |   ├── server/
|   |   |   ├── ...
|   |   |
|   |   ├── src/
|   |   |   ├── ...
|   |
|   ├── news_scrappers/ # Каталог функций по сбору данных с веб ресурсов
|   |   ├── .../
|   |
|   ├── tools/ # Каталог вспомогательных функций
|   |   ├── .../
|   |
|   ├── .env # Конфигурационный файл для скраппера
|   ├── config.py # Файл настройки проекта
|   ├── README.md
|   ├── requirements.txt # Файл зависимостей для скраппера
|   ├── scrapper.py # Сборщик данных
|   ├── start.py # Файл запуска сервера
|
├── .env # Глобальный конфигурационный файл
├── .gitignore
├── README.md
```

**ml_news_classifier**

Каталог проекта по обучению модели МО. 



### Конфигурация
Весь проект разделен на несколько подпроектов. Каждый из них имеет своё описание и инструкции по настройке. Каждый проект можно использовать и разместить на различных серверах. Взаимодействие между ними осуществляется через API. Если же вы используете один сервер для запуска всех подпроектов, то вы можете использовать один, глобальный файл кофигурации.

Пример глобального конфигурационного файла:

```
GLOBAL_SCRAPPER_SERVER_PORT=3131
GLOBAL_SCRAPPER_SERVER_GET_NEWS_DATA_API_PATH=/api/v1/news
```

### Использование



### Технологии

